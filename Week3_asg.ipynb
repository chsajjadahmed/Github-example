{"cells":[{"metadata":{"collapsed":true},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\nimport lxml.html as lh\nimport pandas as pd\nimport numpy as np\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nprint('Libraries imported.')","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting package metadata: failed\n\nCondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://repo.anaconda.com/pkgs/free/linux-64/repodata.json.bz2>\nElapsed: -\n\nAn HTTP error occurred when trying to retrieve this URL.\nHTTP errors are often intermittent, and a simple retry will get you on your way.\n\nIf your current network has https://www.anaconda.com blocked, please file\na support request with your network engineering team.\n\nConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='repo.anaconda.com', port=443): Max retries exceeded with url: /pkgs/free/linux-64/repodata.json.bz2 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f807711b710>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))\",),)\n\n\nLibraries imported.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Scraping the Wikipedia page"},{"metadata":{"trusted":false},"cell_type":"code","source":"url='https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n\n#Create a handle, page, to handle the contents of the website\npage = requests.get(url)\n\n#Store the contents of the website under doc\ndoc = lh.fromstring(page.content)\n\n#Parse data that are stored between <tr>..</tr> of HTML\ntr_elements = doc.xpath('//tr')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"[len(T) for T in tr_elements[:12]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tr_elements = doc.xpath('//tr')\n#Create empty list\ncol=[]\ni=0\n#For each row, store each first element (header) and an empty list\nfor t in tr_elements[0]:\n    i+=1\n    name=t.text_content()\n    print ('%d:\"%s\"'%(i,name))\n    col.append((name,[]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Since out first row is the header, data is stored on the second row onwards\nfor j in range(1,len(tr_elements)):\n    #T is our j'th row\n    T=tr_elements[j]\n    \n    #If row is not of size 10, the //tr data is not from our table \n    if len(T)!=3:\n        break\n    \n    #i is the index of our column\n    i=0\n    \n    #Iterate through each element of the row\n    for t in T.iterchildren():\n        data=t.text_content() \n        #Check if row is empty\n        if i>0:\n        #Convert any numerical value to integers\n            try:\n                data=int(data)\n            except:\n                pass\n        #Append the data to the empty list of the i'th column\n        col[i][1].append(data)\n        #Increment i for the next column\n        i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"[len(C) for (title,C) in col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"Dict={title:column for (title,column) in col}\ndf=pd.DataFrame(Dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.columns = ['Borough', 'Neighborhood', 'Postal Code']\ndf = df[['Postal Code', 'Borough', 'Neighborhood']]\ndf['Neighborhood'] = df['Neighborhood'].map(lambda x: x.rstrip('\\n'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ignore cells with a borough that is Not assigned"},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df[~df.Borough.str.contains(\"Not assigned\")]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Two rows are combined into one row with the neighborhoods separated with a comma where postal code is listed twice"},{"metadata":{"trusted":false},"cell_type":"code","source":"df = df.groupby(['Postal Code', 'Borough'], as_index=False, sort=False).agg(','. join)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## If a cell has a borough but a Not assigned neighborhood, then the neighborhood will be the same as the borough"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Create a list of indices of the cells where the value of Column2 is \"Not assigned\"\nidx_to_change = df.loc[df['Neighborhood'] == \"Not assigned\"].index\n\n# Iterate the list of indicies and set Column2 to the value of Column1 at the given index\nfor i in idx_to_change:\n    df.iloc[i, 2] = df.iloc[i, 1] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Downloading a csv file that has the geographical coordinates of each postal code"},{"metadata":{"trusted":false},"cell_type":"code","source":"!wget -O Location.csv http://cocl.us/Geospatial_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_loc = pd.read_csv('Location.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_loc.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merging two data frames"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_new = pd.merge(df, df_loc, on='Postal Code', how='outer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_new.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Working with only boroughs that contain the word Toronto "},{"metadata":{"trusted":false},"cell_type":"code","source":"toronto_data = df_new[df_new['Borough'].str.contains(\"Toronto\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"toronto_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use geopy library to get the latitude and longitude values of Toronto City"},{"metadata":{"trusted":false},"cell_type":"code","source":"address = 'Toronto, Toronto'\n\ngeolocator = Nominatim(user_agent=\"toronto_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinates of Toronto are {}, {}.'.format(latitude, longitude))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create a map of Toronto with neighborhoods superimposed on top"},{"metadata":{"trusted":false},"cell_type":"code","source":"# create map of Toronto using latitude and longitude values\nmap_toronto = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# add markers to map\nfor lat, lng, label in zip(toronto_data['Latitude'], toronto_data['Longitude'], toronto_data['Neighborhood']):\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Foursquare Credentials and Version"},{"metadata":{"trusted":false},"cell_type":"code","source":"CLIENT_ID = '' #Foursquare ID\nCLIENT_SECRET = '' #Foursquare Secret\nVERSION = '20180605' # Foursquare API version\nLIMIT = 100","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"toronto_venues = getNearbyVenues(names=toronto_data['Neighborhood'],\n                                   latitudes=toronto_data['Latitude'],\n                                   longitudes=toronto_data['Longitude']\n                                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(toronto_venues.shape)\ntoronto_venues.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"toronto_venues.groupby('Neighborhood').count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('There are {} unique categories.'.format(len(toronto_venues['Venue Category'].unique())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One hot encoding"},{"metadata":{"trusted":false},"cell_type":"code","source":"# one hot encoding\ntoronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ntoronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] \n\n# move neighborhood column to the first column\ncol_list = list(toronto_onehot.columns)\ncol_list.remove('Neighborhood')\ncols = ['Neighborhood'] + [col for col in col_list]\n\ntoronto_onehot = toronto_onehot[cols]\ntoronto_onehot.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\ntoronto_grouped","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Printing each neighborhood along with the top 5 most common venues"},{"metadata":{"trusted":false},"cell_type":"code","source":"num_top_venues = 5\n\nfor hood in toronto_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = toronto_grouped[toronto_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Writing a function to sort the venues in descending order"},{"metadata":{"trusted":false},"cell_type":"code","source":"def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating the new dataframe and display the top 10 venues for each neighborhood"},{"metadata":{"trusted":false},"cell_type":"code","source":"num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood']\n\nfor ind in np.arange(toronto_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cluster Neighborhoods"},{"metadata":{"trusted":false},"cell_type":"code","source":"# set number of clusters\nkclusters = 5\n\ntoronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:50] ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood"},{"metadata":{"trusted":false},"cell_type":"code","source":"# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\ntoronto_merged = toronto_data\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntoronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\ntoronto_merged.head() # check the last columns!","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualizing the resulting clusters"},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cluster 1"},{"metadata":{"trusted":false},"cell_type":"code","source":"toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cluster 2"},{"metadata":{"trusted":false},"cell_type":"code","source":"toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cluster 3"},{"metadata":{"trusted":false},"cell_type":"code","source":"toronto_merged.loc[toronto_merged['Cluster Labels'] == 2, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cluster 4 "},{"metadata":{"trusted":false},"cell_type":"code","source":"toronto_merged.loc[toronto_merged['Cluster Labels'] == 3, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cluster 5"},{"metadata":{"trusted":false},"cell_type":"code","source":"toronto_merged.loc[toronto_merged['Cluster Labels'] == 4, toronto_merged.columns[[1] + list(range(5, toronto_merged.shape[1]))]]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.5","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"}},"nbformat":4,"nbformat_minor":1}